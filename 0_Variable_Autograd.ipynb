{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable # torch의 automatic gradient calculate하는 부분에서 variable을 가지고 옴."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00, 1.8264e-37, 1.4013e-45],\n",
       "        [1.4013e-45, 0.0000e+00,        nan,        nan],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7551e-40]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tensor=torch.Tensor(3,4)\n",
    "x_tensor #x_tensor.data 사용할 수 없음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00, 1.8264e-37, 1.4013e-45],\n",
       "        [1.4013e-45, 0.0000e+00,        nan,        nan],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7551e-40]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_variable= Variable(x_tensor) #variable로 감싸주면 값은 똑같아 보이지만 사실 variable이라는 class로 감싸져 있는 것임. \n",
    "x_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00, 1.8264e-37, 1.4013e-45],\n",
       "        [1.4013e-45, 0.0000e+00,        nan,        nan],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7551e-40]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#.data -> wrapped tensor\n",
    "x_variable.data #tensor값들이 들어가게 됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "#.grad ->gradient of the variable\n",
    "print(x_variable.grad) # gradient값도 저장이됨. 아직 연산이 진행되지 않았기 때문에 None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#.requires_grad -> whether variable requires gradient. gradient를 계산할 지 말지의 여부가 들어가 있는 것임.\n",
    "print(x_variable.requires_grad)\n",
    "\n",
    "x_variable=Variable(x_tensor,requires_grad=True) #처음에 만들 때 gradient를 계산할 지 말지 정함.\n",
    "x_variable.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imyeonghui/anaconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  import sys\n",
      "/Users/imyeonghui/anaconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: volatile was removed (Variable.volatile is always False)\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, False, False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#.volatile -> inference mode with minimal memory usage #medel를 학습하고 테스트할 때 inference 할 때 많이 쓰는 것. \n",
    "#불필요한 연산 제거하고 앞으로 feed forward만 하게 최적화시키는 것\n",
    "#전체 연상 graph에 volatile이 하나라도 있으면 전체가 inference mode로 바뀜\n",
    "#single volatile variable makes whole graph not requiring gradient -> requires_grad도 자동 false로 바뀜.\n",
    "#테스트할 때 값을 빨리빨리 확인해 볼 수 있음.\n",
    "\n",
    "x_variable=Variable(x_tensor,volatile=True)\n",
    "x_variable.grad, x_variable.requires_grad, x_variable.volatile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
